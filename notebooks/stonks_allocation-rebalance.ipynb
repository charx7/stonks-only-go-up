{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "modified-repeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/charx/python-virtual-environments/stonks-env/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "alert-airfare",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stonks.data.test_imports import say_hello\n",
    "from pandas_datareader import data\n",
    "\n",
    "\n",
    "# vanilla markotwitz + l2 regularized\n",
    "from pypfopt.expected_returns import mean_historical_return\n",
    "from pypfopt.risk_models import CovarianceShrinkage\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import objective_functions \n",
    "\n",
    "\n",
    "# black litterman model\n",
    "from pypfopt import black_litterman\n",
    "from pypfopt.black_litterman import BlackLittermanModel\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "uniform-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = [\n",
    "    'AAPL', # Apple -> tech\n",
    "    'TSLA', # Tesla -> tech\n",
    "    'GOOGL', # Google -> tech\n",
    "    'AMZN', # Amazon -> consumer/tech\n",
    "    'MA', # MasterCard -> finance\n",
    "    'V', # Visa -> finance\n",
    "    'MELI', # MercadoLibre -> consumer\n",
    "    'NVDA', # Nvidia -> chips\n",
    "    'ASML', # ASML -> chips\n",
    "    'FB' # facebook -> social media\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "neural-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We would like all available data from 01/01/2000 until 12/31/2016.\n",
    "start_date = '2008-01-01'\n",
    "end_date = '2021-04-05'\n",
    "\n",
    "# possible bug correction\n",
    "# start_date = '01-01-2010'\n",
    "# end_date = '03-07-2021'\n",
    "# start = datetime.datetime.strptime(start_date, '%d-%m-%Y')\n",
    "# end = datetime.datetime.strptime(end_date, '%d-%m-%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adequate-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single ticker dload doesnt work!!\n",
    "# curr_df = data.DataReader('GOOG', 'yahoo', start, end) # test the yf downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extensive-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    }
   ],
   "source": [
    "# legacy version to read data\n",
    "# price_data = []\n",
    "# for ticker in tickers:\n",
    "#     print(ticker)\n",
    "#     curr_df = data.DataReader(ticker, 'yahoo', start_date, end_date)\n",
    "#     time.sleep(0.3)\n",
    "#     price_data.append(curr_df['Adj Close'])\n",
    "\n",
    "# # construct a df with the company values\n",
    "# df_stocks = pd.concat(price_data, axis = 1)\n",
    "# df_stocks.columns = tickers\n",
    "\n",
    "tmp = pd.DataFrame(yf.download(tickers,start=start_date,end=end_date))\n",
    "df_stocks = tmp['Adj Close']\n",
    "df_stocks = df_stocks.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "smoking-novel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEGACY -> using pandas bfill method now\n",
    "def back_fill_df(df, verbose = True):\n",
    "    df_cp = df.copy()\n",
    "    \n",
    "    tkrs = list(df.columns)\n",
    "    \n",
    "    for tiker in tkrs:\n",
    "        print(f'Backfilling: {tiker}') if verbose else 'continue'\n",
    "        #srs = df_cp[df_cp[tiker].isnull()][tiker]\n",
    "        srs = df_cp[~df_cp[tiker].isnull()][tiker]\n",
    "\n",
    "        # only do the backfill if the series requires it\n",
    "        if srs.shape[0] > 0:\n",
    "            bkfill_val = srs[0]\n",
    "            \n",
    "            print(f\"Backfilldate {srs.index[0]}\") if verbose else 'continue'\n",
    "            #bkfill_val = df_cp[df_cp.index == last_nan + pd.DateOffset(1)][ticker][0]\n",
    "            \n",
    "            print(f\"Backfilling with {bkfill_val}\") if verbose else 'continue'\n",
    "            df_cp[tiker] = df_cp[tiker].fillna(value = bkfill_val)\n",
    "    \n",
    "    return df_cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "visible-fellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEGACY backfill method\n",
    "#df_stocks_bkfilled = back_fill_df(df_stocks, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "opening-ambassador",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3337, 10)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_stocks_bkfilled = df_stocks\n",
    "df_stocks_bkfilled.shape\n",
    "#df_stocks_bkfilled = 12\n",
    "\n",
    "# try:\n",
    "#     assert df_stocks_bkfilled.empty == False\n",
    "# except AssertionError:\n",
    "#     print(\"The df is empty :(\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "studied-subscriber",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('AAPL', 0.11133), ('AMZN', 0.14094), ('ASML', 0.12624), ('FB', 0.07028), ('GOOGL', 0.01964), ('MA', 0.09401), ('MELI', 0.0556), ('NVDA', 0.05144), ('TSLA', 0.22766), ('V', 0.10285)])\n",
      "Expected annual return: 30.0%\n",
      "Annual volatility: 26.4%\n",
      "Sharpe Ratio: 1.06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charx/python-virtual-environments/stonks-env/lib/python3.7/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:248: UserWarning: max_sharpe transforms the optimization problem so additional objectives may not work as expected.\n",
      "  \"max_sharpe transforms the optimization problem so additional objectives may not work as expected.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2998621747002599, 0.2636093550703512, 1.0616549425022157)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get mean and cover matrices\n",
    "mu = mean_historical_return(df_stocks_bkfilled)\n",
    "S = CovarianceShrinkage(df_stocks_bkfilled).ledoit_wolf()\n",
    "\n",
    "# with l2 regularization to not have 0s in the weights\n",
    "\n",
    "ef = EfficientFrontier(mu, S)\n",
    "ef.add_objective(objective_functions.L2_reg, gamma=0.5)\n",
    "w = ef.max_sharpe()\n",
    "\n",
    "cleaned_weights = ef.clean_weights()\n",
    "ef.save_weights_to_file(\"weights.txt\")  # saves to file\n",
    "print(cleaned_weights)\n",
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-mitchell",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fixed-creativity",
   "metadata": {},
   "source": [
    "# Black litterman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "advised-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "mcaps = {}\n",
    "for t in tickers:\n",
    "    stock = yf.Ticker(t)\n",
    "    mcaps[t] = stock.info[\"marketCap\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "removable-change",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AAPL': 2151114997760,\n",
       " 'TSLA': 649101508608,\n",
       " 'GOOGL': 1572586389504,\n",
       " 'AMZN': 1657491161088,\n",
       " 'MA': 369596104704,\n",
       " 'V': 506987249664,\n",
       " 'MELI': 77152419840,\n",
       " 'NVDA': 374639132672,\n",
       " 'ASML': 264838168576,\n",
       " 'FB': 898004353024}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mcaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "molecular-scott",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "Expected annual return: 28.2%\n",
      "Annual volatility: 25.8%\n",
      "Sharpe Ratio: 1.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/charx/python-virtual-environments/stonks-env/lib/python3.7/site-packages/pypfopt/efficient_frontier/efficient_frontier.py:248: UserWarning: max_sharpe transforms the optimization problem so additional objectives may not work as expected.\n",
      "  \"max_sharpe transforms the optimization problem so additional objectives may not work as expected.\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.2820280065130128, 0.25831918328018505, 1.0143575215194334)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the market prices of the sp500\n",
    "sp500 = yf.download(\"SPY\", period=\"max\")[\"Adj Close\"]\n",
    "\n",
    "# declare our views of the market\n",
    "viewdict = {\n",
    "    \"GOOGL\": 0.30,\n",
    "    \"FB\": 0.30,\n",
    "    \"ASML\": 0.30,\n",
    "    \"NVDA\": 0.30,\n",
    "}\n",
    "\n",
    "# how confident we are on our views\n",
    "confidences = [\n",
    "    0.8,\n",
    "    0.8,\n",
    "    0.6,\n",
    "    0.6,\n",
    "]\n",
    "# confidences = [\n",
    "#     0.3,\n",
    "#     0.8,\n",
    "#     0.8,\n",
    "#     0.7,\n",
    "#     0.8,\n",
    "#     0.5,\n",
    "#     0.6,\n",
    "#     0.7,\n",
    "#     0.8,\n",
    "#     0.9,\n",
    "#     0.9,\n",
    "# ]\n",
    "\n",
    "\n",
    "S = CovarianceShrinkage(df_stocks_bkfilled).ledoit_wolf()\n",
    "delta = black_litterman.market_implied_risk_aversion(sp500)\n",
    "\n",
    "# get market priors\n",
    "market_prior = black_litterman.market_implied_prior_returns(mcaps, delta, S)\n",
    "\n",
    "# blmodel\n",
    "bl = BlackLittermanModel(S, pi = market_prior, absolute_views = viewdict, risk_aversion = delta, omega=\"idzorek\", view_confidences=confidences)\n",
    "#bl = BlackLittermanModel(S, pi = market_prior, risk_aversion = delta, omega=\"idzorek\")\n",
    "\n",
    "\n",
    "ret_bl = bl.bl_returns() # mean matrix for black litterman\n",
    "S_bl = bl.bl_cov() # co-variance matrix for black litterman\n",
    "\n",
    "\n",
    "# then we allocate the portfolio using markowitz regularized\n",
    "ef = EfficientFrontier(ret_bl, S_bl)\n",
    "#ef.add_objective(objective_functions.L2_reg, gamma = 0.5)\n",
    "ef.add_objective(objective_functions.L2_reg)\n",
    "\n",
    "ef.max_sharpe()\n",
    "weights = ef.clean_weights()\n",
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "equal-hybrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL pct: 0.10369 amnt: 247.56091189999998\n",
      "TSLA pct: 0.08624 amnt: 205.89886239999998\n",
      "GOOGL pct: 0.11307 amnt: 269.9557557\n",
      "AMZN pct: 0.1167 amnt: 278.622417\n",
      "MA pct: 0.08609 amnt: 205.5407359\n",
      "V pct: 0.07667 amnt: 183.05039169999998\n",
      "MELI pct: 0.09993 amnt: 238.5838743\n",
      "NVDA pct: 0.10203 amnt: 243.59764529999995\n",
      "ASML pct: 0.09479 amnt: 226.31207289999998\n",
      "FB pct: 0.12079 amnt: 288.38733289999993\n"
     ]
    }
   ],
   "source": [
    "capital = 2401.79\n",
    "capital = capital - 14.28\n",
    "\n",
    "total = 0\n",
    "for k, v in weights.items():\n",
    "    total += capital * v\n",
    "    print(f\"{k} pct: {v} amnt: {capital * v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "subsequent-chassis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL pct: 0.10369 amnt: 186.18991160000002\n",
      "TSLA pct: 0.08624 amnt: 154.8559936\n",
      "GOOGL pct: 0.11307 amnt: 203.03301480000002\n",
      "AMZN pct: 0.1167 amnt: 209.551188\n",
      "MA pct: 0.08609 amnt: 154.58664760000002\n",
      "V pct: 0.07667 amnt: 137.6717188\n",
      "MELI pct: 0.09993 amnt: 179.43830520000003\n",
      "NVDA pct: 0.10203 amnt: 183.2091492\n",
      "ASML pct: 0.09479 amnt: 170.2087156\n",
      "FB pct: 0.12079 amnt: 216.89535560000002\n"
     ]
    }
   ],
   "source": [
    "capital = 1809.92\n",
    "capital = capital - 14.28\n",
    "\n",
    "total = 0\n",
    "for k, v in weights.items():\n",
    "    total += capital * v\n",
    "    print(f\"{k} pct: {v} amnt: {capital * v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-surname",
   "metadata": {},
   "source": [
    "# VaR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "expanded-flavor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backfilldate 2019-09-19 00:00:00\n",
    "# new backfill date 2012-05-18 00:00:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "demographic-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_stocks_bkfilled.copy()\n",
    "#df_var = df[df.index > '2019-09-19']\n",
    "df_var = df[df.index > '2012-05-18']\n",
    "\n",
    "# get the % vals of the stocks\n",
    "weights_lst = list(weights.values())\n",
    "weights_array = np.array(weights_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "norwegian-swaziland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sh_wt\n",
    "#historic_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "tropical-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_var = df_var.pct_change().iloc[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "competitive-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PnL = (weights * returns.values).sum(axis=1)\n",
    "# calculate the daily historic PnL of the portfolio\n",
    "hist_daily_portfolio_PnL = (weights_array * df_var.values).sum(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "frank-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The historic VaR is: -0.023620926415302848\n",
      "The simple historical VaR pandors is -14.125313996351103\n",
      "The simple historical VaR puerquits is -112.63638761137163\n"
     ]
    }
   ],
   "source": [
    "historic_var = np.percentile(hist_daily_portfolio_PnL, 5, interpolation=\"lower\")\n",
    "print(f\"The historic VaR is: {historic_var}\")\n",
    "\n",
    "capital_pandors = 598\n",
    "capital_puerquits = 4768.50\n",
    "\n",
    "print(f'The simple historical VaR pandors is {historic_var * capital_pandors}')\n",
    "print(f'The simple historical VaR puerquits is {historic_var * capital_puerquits}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hawaiian-diary",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "under-conversion",
   "metadata": {},
   "source": [
    "# CVAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "colored-midnight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cvar of the portfolio is: -0.035916581778095306\n",
      "The simple historical CVaR pandors is -21.478115903300992\n",
      "The simple historical VaR puerquits is -171.26822020884748\n"
     ]
    }
   ],
   "source": [
    "# filter all values with loses greater than the historic var\n",
    "cvar = hist_daily_portfolio_PnL[hist_daily_portfolio_PnL <= historic_var]\n",
    "print(f'The cvar of the portfolio is: {cvar.mean()}')\n",
    "print(f'The simple historical CVaR pandors is {cvar.mean() * capital_pandors}')\n",
    "print(f'The simple historical VaR puerquits is {cvar.mean() * capital_puerquits}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-intro",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
